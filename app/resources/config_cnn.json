{
    "reqid": "20190430213914",
    "models": {
        "Model1": {
            "modelPath": "cnn",
            "modelType": "keras",
            "handleType": "charVectors"
        }
    },
    "tokenization": {
        "actualtoks": "yes",
        "normalization": "yes",
        "stopwords": "yes",
        "expos": "PUNC,DT,IN,CD,PRP,RP,RB,W,PDT",
        "extrawords": "",
        "maxseqlen": 300,
        "maxcharsseqlen": 512,
        "rttaggerpath": "ArabicDocumentsTokenizer.jar"
    },
    "labels": "labels.txt"
}